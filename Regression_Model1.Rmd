---
title: "Regression-Model 1"
output: 
  html_document: 
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readr)
library(readxl)
library(kableExtra)
library(knitr)
library(plotly)

knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%",
  message = FALSE,
  warning = FALSE
)

theme_set(theme_light() + theme(legend.position = "bottom"))

options(knitr.table.format = "html")
```

```{r, echo=FALSE}
main_df <- 
  read_csv("./data/maindata.csv")

main_df <- 
  main_df %>% 
  mutate(year = lubridate::year(date_of_death)) %>% 
  filter(year != 2021)
```

```{r, echo=FALSE}
pop_stat <- 
  read_csv("data/census.csv")
```

```{r, echo=FALSE}
gun_owner <- 
  read_csv("data/Gun Ownership by State 2021.csv") %>% 
  janitor::clean_names() %>% 
  select(-total_guns)
```

```{r, echo=FALSE}
crime_stat <- 
  read_excel("data/reported-violent-crime-rate-in-the-us-2020-by-state.xlsx", 
             sheet = "Data",
             range = "B5:C57") %>%
  rename(state = 1, crime_per_10e6 = 2) %>% 
  filter(state != "United States") %>% 
  mutate(crime_per_10e6 = as.numeric(crime_per_10e6))
```

```{r, echo=FALSE}
unempolyment_stat <- 
  read_excel("data/state-unemployment-rate-in-the-us-2020.xlsx", 
             sheet = "Data",
             range = "B5:C56") %>% 
  rename(state = 1, unemploy_rate = 2) %>% 
  mutate(unemploy_rate = as.numeric(unemploy_rate)/100)
```


---------------------------------------------------

### Description

In this study, we are curious about the association between innocent death rate by police and potential factors. In this case, innocent death(per 10K) will be considered as dependent variable while some interests will be regarded as predictors so that multiple linear regression will be used to testify and assess whether the correlation is significant or not.

+ For Model 1, predictors and variables are below:
  + **innocent death(per 10K):** count of innocent death divided by state population and multiplied by 10K
  + **year:** the year of death(2010 - 2020)
  + **state:** the best state location where the injury causing death happened that we can find using Google Maps.
  + **age_bin:** age divided into 6 groups(0-14, 15-24, 25-34, 35-54, 55-85, 85+)
  + **gender:** Male, Female
  + **race:** Usually based on visual evidence or official reports(European-American/White, African-American/Black, Native American/Alaskan, Asian/Pacific Islander, Hispanic/Latino)

---------------------------------------------------

### Explorative Graphs

In order to completely comprehensive the model 1, the distribution of predictors and variables (innocent death number, sex, age group, race) are plotted below from 2010 to 2020 and there's a phenomenon that the proportion in each predictor is also consistent. For more analysis, you could jump to trend plot part.

```{r}
year_plot =
  main_df %>%
  filter(year %in% c(2010:2020)) %>%
  group_by(year) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = year, y = count, fill = as.factor(year))) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = c(2010:2020)) +
  scale_fill_manual(
    values = c(
      "#CC543A",
      "#E9A368",
      "#b98b73",
      "#cb997e",
      "#ddbea9",
      "#ffe8d6",
      "#d4c7b0",
      "#b7b7a4",
      "#a5a58d",
      "#6b705c",
      "#3f4238"
    )
  ) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45),
        axis.title.x = element_blank()) 

sex_plot = 
  main_df %>% 
  filter(year %in% c(2010:2020)) %>% 
  group_by(year, gender) %>% 
  summarize(count = n()) %>% 
  ggplot(aes(x = year, y = count, fill = gender)) + 
  geom_bar(stat = "identity", position = position_dodge()) +
  scale_x_continuous(breaks = c(2010:2020)) +
  scale_fill_manual(values = c("#cb997e", "#867835"), labels = c("Female", "Male")) +
  theme(legend.title = element_blank(),
        axis.text.x = element_text(angle = 45),
        axis.title.x = element_blank())

age_plot = 
  main_df %>%
  filter(year %in% c(2010:2020)) %>%
  group_by(year, age_bin) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = year, y = count, fill = age_bin)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = c(2010:2020)) +
  scale_fill_manual(values = c("#a3a380","#d6ce93","#efebce","#d8a48f","#bb8588", "#f48498")) +
  theme(
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 45),
    axis.title.x = element_blank()
  ) +
  guides(fill = guide_legend(ncol = 6))

race_plot = 
  main_df %>%
  filter(year %in% c(2010:2020)) %>%
  group_by(year, race) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = year, y = count, fill = race)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = c(2010:2020)) +
  scale_fill_manual(values = c("#a3a380","#d6ce93","#efebce","#d8a48f","#bb8588")) +
  theme(
    legend.title = element_blank(),
    axis.text.x = element_text(angle = 45),
    axis.title.x = element_blank()
  ) +
  guides(fill = guide_legend(ncol = 3))
```


```{r}

combination_plt =
  subplot(
    ggplotly(year_plot),
    ggplotly(sex_plot),
    ggplotly(age_plot),
    ggplotly(race_plot),
    nrows = 2,
    titleY = TRUE,
    titleX = TRUE,
    margin = 0.1
  ) 

annotations = list( 
  list( 
    x = 0.2,  
    y = 1.0,  
    text = "Year",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),  
  list( 
    x = 0.8,  
    y = 1,  
    text = "Sex",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),  
  list( 
    x = 0.2,  
    y = 0.45,  
    text = "Age",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),
  list( 
    x = 0.8,  
    y = 0.45,  
    text = "Race",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ))

  
combination_plt =
  combination_plt %>%
  layout(showlegend = F, annotations = annotations)

combination_plt
```

---------------------------------------------------

### Statistical Analysis

```{r, echo=FALSE}
reg_df1 <- 
  main_df %>% 
  group_by(year, state, age_bin, gender, race) %>% 
  summarize(count = n()) %>% 
  filter(year %in% c(2010:2020), state != "DC") %>% 
  left_join(pop_stat, by = c("year", "state", "age_bin", "gender", "race")) %>% 
  mutate(innocent_kill_per100k = count / population * 10^5)
```

#### 1.Distribution of dependent variable(innocent death(per 10K))

The density plot below is the distribution of innocent death(per 10K) which we notice it is not satisfied of the assumption of the multiple linear regression so that we need to transform it.

```{r}
# Find distribution of the target variable `innocent_kill_per100k`
reg_df1 %>% 
  ggplot(aes(x = innocent_kill_per100k)) + 
  geom_density(color = "dodgerblue1", fill = "skyblue2") + 
  geom_vline(xintercept = mean(reg_df1$innocent_kill_per100k), linetype = "dotted") +
  labs(x = "innocent death(per 10K)")
```

#### 2.Transformation

In order to get normal distribution, here we conduct log transformation. The plot followed is what we get by transformation and it almost satisfies the assumption of the multiple linear regression

```{r}
# After transformation
reg_df1 %>% 
  ggplot(aes(x = log(innocent_kill_per100k))) + 
  geom_density(color = "dodgerblue1", fill = "skyblue2") + 
  geom_vline(xintercept = mean(log(reg_df1$innocent_kill_per100k)), linetype = "dotted") + 
  labs(x = "log(innocent death per 10K)")
```

#### 3.Modeling

By transformation above, the formula is below:

$$ log(innocent \space death \space per \space 100k) = \beta_0 + \beta_1year + \beta_2state + \beta_3 age + \beta_4 gender + \beta_5 race$$

```{r}
# Model 1 -- across all years in database
# Fit a model
fit1 <- lm(log(innocent_kill_per100k) ~ year + state + age_bin + gender + race, data = reg_df1)

summary(fit1) %>% 
  broom::tidy() %>% 
  knitr::kable() %>%
  kable_styling() %>% 
  scroll_box(height = "200px")

summary(fit1) %>% 
  broom::glance() %>% 
  knitr::kable() %>% 
  kable_styling()
```

Based on the summary and statistics in the table above, we could conclude that all all predictor are significant in statistical aspect although some levels in state have no significant association.


When concentrating on the table of R.squared, we could figure out that $R^2$ value is 0.72 which means that 72% of the variability in the outcome data can be explained by the model, especially if R-squared value r > 0.7 this value is generally considered strong effect size *(Ref:Moore, D. S., Notz, W. I, & Flinger, M. A. (2013). The basic practice of statistics (6th ed.))*

#### 4.MLR dignostics

In order to further make sure the accuracy of model 1 and the homoscedasticity of residual, we draw four pictures which are Residuals vs Fitted, Normal QQ, Scale-Location and Residuals vs Leverage respectively.

* Residuals vs Fitted: show that we have equally spread residuals around a horizontal line without distinct patterns which indicate it has linear relationship
* Q-Q plot: Use for examining the normality assumption which is satisfied here
* Scale-Location: The assumption of homoscedasticity has been checked in that we can see a horizontal line with equally spread points.
* Residuals vs Leverage: shows that there's no too many outlier points and influential points in the plot.


```{r}
# Model diagnosis
par(mfrow = c(2, 2))
plot(fit1)
```



<font size="5"><a href = "#top" target = "_self">Back to top</a></font>